import streamlit as st
from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig
import time
from services import speech_fast_transcription, llm_analysis, aoai_audio
from styles import get_file_uploader_style

@st.fragment
def download_transcription():
    st.download_button(
        label="ä¸‹è½½éŸ³é¢‘è½¬å½•",
        icon="ğŸ“¥",
        data=transcription.encode('utf-8'),
        file_name=f"transcription_{time.strftime('%Y%m%d_%H%M%S')}.txt",
        mime="text/plain",
        key="download_transcription"
    )

transcription_tools = {
    "fast_transcription": {
        "name": "Azure Speech Fast Transcription",
        "function": speech_fast_transcription.fast_transcript,
        "limit": {
            "file_size": 200,  # 200 MB
            "duration": "2 hours",  # 2 hours
        }
    },
    "gpt4o_transcribe": {
        "name": "GPT-4o-transcribe",
        "function": aoai_audio.transcribe,
        "limit": {
            "file_size": 25,  # 25 MB
            "duration": "10 min",  # Officially anounced 1500s, but with bug
        }
    }
}

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="ä¼šè®®å½•è½¬æ‘˜", page_icon="ğŸ—“ï¸", layout="centered")
st.title("ğŸ—“ï¸ ä¼šè®®å½•è½¬æ‘˜")
st.markdown(get_file_uploader_style(), unsafe_allow_html=True)

tool_names = [tool["name"] for tool in transcription_tools.values()]
tool_keys = list(transcription_tools.keys())
selected_tool_name = st.radio(
    "é€‰æ‹©éŸ³é¢‘è½¬å½•å·¥å…·",
    tool_names,
    index=0,
    horizontal=True
)
transcription_tool = tool_keys[tool_names.index(selected_tool_name)]

audio_limit = transcription_tools[transcription_tool]["limit"]
audio_limit_msg = f"Audio file size limit: {audio_limit['file_size']} MB, audio length limit: {audio_limit['duration']}"
audio_file = st.file_uploader("ğŸ¤ ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", type=["wav", "mp3", "m4a"])
st.caption(audio_limit_msg)

if audio_file is not None:
    file_size_bytes = audio_file.size
    file_size_mb = file_size_bytes / (1024 * 1024)  # Convert bytes to MB
    if file_size_mb > audio_limit["file_size"]:
        st.error(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼š{audio_limit['file_size']} MB")
        audio_file = None

image_limit = 20
image_limit_msg = f"Image size limit: {image_limit} MB"
image_file = st.file_uploader("ğŸ–¼ï¸ ä¸Šä¼ å›¾åƒæ–‡ä»¶", type=["jpg", "jpeg", "png"])
st.caption(image_limit_msg)

if image_file is not None:
    file_size_bytes = image_file.size
    file_size_mb = file_size_bytes / (1024 * 1024)  # Convert bytes to MB
    if file_size_mb > image_limit:
        st.error(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼š{image_limit} MB")
        image_file = None

user_prompt = st.text_input("ğŸ“ è¾“å…¥æç¤ºè¯ï¼Œç”¨äºä¼šè®®æ€»ç»“ (Optional)")

if st.button("ğŸš€ å¤„ç†") and (audio_file or image_file):
    transcription = None
    image_result = None
    has_next = True
    with st.spinner("å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."):
        # è½¬å½•éŸ³é¢‘
        
        if audio_file:
            start = time.time()
            result = speech_fast_transcription.fast_transcript(audio_file)
            elapsed_audio = time.time() - start

            if result:
                transcription = result
                st.sidebar.success(f"éŸ³é¢‘è½¬å½•å®Œæˆï¼Œè€—æ—¶ {elapsed_audio:.2f} ç§’")
                st.subheader("ğŸ¤ éŸ³é¢‘è½¬å½•")
                download_transcription()
            else:
                transcription = None
                st.sidebar.error("è½¬å½•å¤±è´¥ã€‚è¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ ¼å¼æˆ–è´¨é‡ã€‚")
                has_next = False

        # åˆ†æå›¾åƒå†…å®¹
        if image_file:
            start = time.time()
            image_result = llm_analysis.analysis_image(image_file)
            elapsed_image = time.time() - start
            
            if image_result:
                st.sidebar.success(f"å›¾åƒåˆ†æå®Œæˆï¼Œè€—æ—¶ {elapsed_image:.2f} ç§’")
            else:
                image_result = None
                st.sidebar.error("å›¾åƒåˆ†æå¤±è´¥ã€‚è¯·æ£€æŸ¥å›¾åƒæ–‡ä»¶æ ¼å¼æˆ–è´¨é‡ã€‚")
                has_next = False
        
        if has_next:
            # æ€»ç»“å†…å®¹
            summary_prompt = f"""
            éŸ³é¢‘è½¬å½•ï¼š{transcription}
            å›¾åƒåˆ†æï¼š{image_result}

            è¯·æä¾›ä¸€ä»½ä¾§é‡äºä¼šè®®å†…å®¹å’Œå¾…åŠäº‹é¡¹çš„æ€»ç»“ã€‚
            """

            start = time.time()
            summary = llm_analysis.analysis_text(user_prompt,summary_prompt)
            elapsed_summary = time.time() - start
            st.sidebar.success(f"ä¼šè®®æ€»ç»“å®Œæˆï¼Œè€—æ—¶ {elapsed_summary:.2f} ç§’")
        
            st.subheader("ğŸ“ ä¼šè®®çºªè¦")
            with st.expander("ç‚¹å‡»æŸ¥çœ‹ä¼šè®®çºªè¦"):
                st.markdown(summary)

